\name{krmm}
\alias{krmm}
\encoding{utf8}

\title{
  Kernel ridge regression in the mixed model framework
}

\description{
  \code{krmm} solves kernel ridge regression for various kernels within the mixed model framework: \eqn{Y = X\beta + Zu + \epsilon}, where \eqn{X} and \eqn{Z} are design matrices of predictors with fixed and random effects, respectively.
}

\usage{
  krmm(Y, X = rep(1, length(Y)), Z = diag(1, length(Y)),
       Matrix_covariates, method = "RKHS", kernel = "Gaussian",
       rate_decay_kernel = 0.1, degree_poly = 2, scale_poly = 1,
       offset_poly = 1, degree_anova = 3,
       init_sigma2K = 2, init_sigma2E = 3, convergence_precision = 1e-08,
       nb_iter = 1000, display = FALSE)
}

\arguments{
  \item{Y}{numeric vector; response vector for training data}
  \item{X}{numeric matrix; design matrix of predictors with fixed effects for training data (default is a vector of ones)}
  \item{Z}{numeric matrix; design matrix of predictors with random effects for training data (default is identity matrix)}
  \item{Matrix_covariates}{numeric matrix; entries for training data used to build the kernel matrix}
  \item{method}{character string; RKHS, GBLUP, or RR-BLUP}
  \item{kernel}{character string; "Gaussian", "Laplacian" or "ANOVA"" (kernels for RKHS regression ONLY, linear kernel for GBLUP and RR-BLUP)}
  \item{rate_decay_kernel}{numeric scalar; hyperparameter of the kernel (default is 0.1)}
  \item{degree_poly, scale_poly, offset_poly}{numeric scalars; parameters for polynomial kernel (defaults are 2, 1, and 1)}
  \item{degree_anova}{numeric scalar; parameter for ANOVA kernel (default is 3)}
  \item{init_sigma2K, init_sigma2E}{numeric scalars; initial guess values for the EM-REML algorithm (defaults are 2 and 3)}
  \item{convergence_precision, nb_iter}{numeric scalars; convergence precision and maximum iterations for the EM-REML algorithm (defaults are 1e-8 and 1000)}
  \item{display}{boolean; display estimated components at each iteration}
}

\details{
  The matrix \code{Matrix_covariates} is mandatory to build the kernel matrix for model estimation and prediction.
}

\value{
  \item{beta_hat}{estimated fixed effect(s)}
  \item{sigma2K_hat, sigma2E_hat}{estimated variance components}
  \item{vect_alpha}{estimated dual variables}
  \item{gamma_hat}{RR-BLUP of covariate effects (available for RR-BLUP method only)}
}

\references{
  Jacquin et al. (2016); Robinson (1991); Foulley (2002)
}

\author{
  Laval Jacquin

  Maintainer: Laval Jacquin <jacquin.julien@gmail.com>
}

\examples{
# load libraries
library(KRMM)

# simulate data
set.seed(123)
p <- 500
n <- 300
gamma <- rnorm(p, mean = 0, sd = 0.5)
M <- matrix(runif(p * n, min = 0, max = 1), ncol = p, byrow = T)  # matrix of covariates
f <- tcrossprod(gamma, M)                                         # data generating process
eps <- rnorm(n, mean = 0, sd = 0.1)                               # add residuals
Y <- f + eps                                                      # data generating process (DGP)

# split data into training and test set
n_train <- floor(n * 0.67)
idx_train <- sample(1:n, size = n_train, replace = F)

# train
M_train <- M[idx_train, ]
y_train <- Y[idx_train]

# train krmm with linear kernel (i.e. dot product)
linear_krmm_model <- krmm(Y = y_train, Matrix_covariates = M_train, method = "RR-BLUP")

summary(linear_krmm_model)
print(linear_krmm_model$beta_hat)
hist(linear_krmm_model$gamma_hat)
hist(linear_krmm_model$vect_alpha)

# train krmm with non linear gaussian kernel (gaussian is the default kernel for RKHS method)
non_linear_krmm_model <- krmm(Y = y_train, Matrix_covariates = M_train, method = "RKHS")

summary(non_linear_krmm_model)
print(non_linear_krmm_model$beta_hat)
hist(non_linear_krmm_model$vect_alpha)

# get test data from matrix of covariates for prediction
M_test <- M[-idx_train, ]

# get unknown true value generated by DGP we want to predict using predict_krmm
f_test <- f[-idx_train]

# -- prediction with linear kernel

# without fixed effects
f_hat_test <- predict_krmm(linear_krmm_model, Matrix_covariates = M_test)
dev.new()
plot(f_hat_test, f_test, main = "Linear RKHS regression without fixed effects")
cor(f_hat_test, f_test)

# with added fixed effects
f_hat_test <- predict_krmm(linear_krmm_model, Matrix_covariates = M_test, add_flxed_effects = T)
dev.new()
plot(f_hat_test, f_test, main = "Linear RKHS regression with fixed effects added")
cor(f_hat_test, f_test)

# -- prediction with non linear gaussian kernel

# without fixed effects
f_hat_test <- predict_krmm(non_linear_krmm_model, Matrix_covariates = M_test)
dev.new()
plot(f_hat_test, f_test, main = "Gaussian RKHS regression without fixed effects,
     and default rate of decay (not optimized)")
cor(f_hat_test, f_test)

# with added fixed effects
f_hat_test <- predict_krmm(non_linear_krmm_model, Matrix_covariates = M_test, add_flxed_effects = T)
dev.new()
plot(f_hat_test, f_test, main = "Gaussian RKHS regression with fixed effects added,
     and default rate of decay (not optimized)")
cor(f_hat_test, f_test)

# -- tune krmm model with a gaussian kernel and make predictions for test data
non_linear_opt_krmm_obj <- tune_krmm(
  Y = y_train, Matrix_covariates = M_train,
  rate_decay_grid = seq(0.01, 0.1, length.out = 5), nb_folds = 3,
  method = "RKHS", kernel = "Gaussian",
)
print(non_linear_opt_krmm_obj$optimal_h)
plot(non_linear_opt_krmm_obj$rate_decay_grid,
     non_linear_opt_krmm_obj$mean_loss_grid, type = "l")

# get the optimized krmm model
non_linear_opt_krmm_model <- non_linear_opt_krmm_obj$optimized_model

# without fixed effects
f_hat_test <- predict_krmm(non_linear_opt_krmm_model, Matrix_covariates = M_test, add_flxed_effects = F)
dev.new()
plot(f_hat_test, f_test, main = "Gaussian RKHS regression with optimized rate of decay")
cor(f_hat_test, f_test)

# with added fixed effects
f_hat_test <- predict_krmm(non_linear_opt_krmm_model, Matrix_covariates = M_test, add_flxed_effects = T)
dev.new()
plot(f_hat_test, f_test, main = "Gaussian RKHS regression with optimized rate of decay")
cor(f_hat_test, f_test)
}
